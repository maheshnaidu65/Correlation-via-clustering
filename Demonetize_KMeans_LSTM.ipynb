{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demonetize-main_LSTM_Github.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKCKLEje13Iq",
        "colab_type": "text"
      },
      "source": [
        "###Forecasting of Retweets for Tweets during Demonetization in India - Program and steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8nYo2NxpUqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import re\n",
        "import nltk\n",
        "import keras\n",
        "from keras.layers import Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from keras import Sequential\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input, Lambda\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx24u7KupUq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading the csv file\n",
        "df = pd.read_csv('demonetization-tweets.csv', encoding = 'unicode-escape')\n",
        "\n",
        "# creating a new dataframe with the relevant columns\n",
        "data = df[['text', 'Time', 'retweetCount' ]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRwOecpYpUrE",
        "colab_type": "code",
        "outputId": "00ed4752-2fe8-4088-e911-d9281f3541b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Time</th>\n",
              "      <th>retweetCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
              "      <td>6:40:30 PM</td>\n",
              "      <td>331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
              "      <td>6:40:29 PM</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
              "      <td>6:40:03 PM</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
              "      <td>6:39:59 PM</td>\n",
              "      <td>338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
              "      <td>6:39:39 PM</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text        Time  retweetCount\n",
              "0  RT @rssurjewala: Critical question: Was PayTM ...  6:40:30 PM           331\n",
              "1  RT @Hemant_80: Did you vote on #Demonetization...  6:40:29 PM            66\n",
              "2  RT @roshankar: Former FinSec, RBI Dy Governor,...  6:40:03 PM            12\n",
              "3  RT @ANI_news: Gurugram (Haryana): Post office ...  6:39:59 PM           338\n",
              "4  RT @satishacharya: Reddy Wedding! @mail_today ...  6:39:39 PM           120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-SrcPTOAOuT",
        "colab_type": "text"
      },
      "source": [
        "**K Means Clustering**\n",
        "\n",
        "The complete Dataset has been divided into four groups based on the number of retweets.\n",
        "All those tweets whose retweets fall in a certain range, will be grouped together. \n",
        "This was done using K-Means. The 'Retweets' attribute is given an input to K-Means function which then groups the number of retweets into four groups.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Husw1jipUrN",
        "colab_type": "code",
        "outputId": "076ae1e9-1a72-4d67-9f88-fe73a742b646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#KMeans clustering\n",
        "X = data.retweetCount.values.reshape(-1,1)\n",
        "kMeans = KMeans(n_clusters=4, random_state = 0).fit(X)\n",
        "\n",
        "#creating a new group with kMeans.labels_\n",
        "data['group'] = kMeans.labels_"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptGIwSe4CsQ2",
        "colab_type": "text"
      },
      "source": [
        "K-Means brings together tweets which are somewhat correlated to each other. This is because the tweets that produce similar number of retweets should have some relationship betwen them. The 4 groups with their respective range of retweets (min, max) are generated below-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKc3jMDTWxa9",
        "colab_type": "code",
        "outputId": "874505d6-a438-4848-a82e-66575c51bf57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "data.groupby(['group']).describe()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">retweetCount</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11561.0</td>\n",
              "      <td>40.684456</td>\n",
              "      <td>54.761859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1722.0</td>\n",
              "      <td>1233.387921</td>\n",
              "      <td>186.720006</td>\n",
              "      <td>862.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>1333.0</td>\n",
              "      <td>1333.0</td>\n",
              "      <td>2507.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1648.0</td>\n",
              "      <td>428.760316</td>\n",
              "      <td>160.371473</td>\n",
              "      <td>237.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>637.0</td>\n",
              "      <td>762.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>4698.000000</td>\n",
              "      <td>708.000000</td>\n",
              "      <td>3754.0</td>\n",
              "      <td>3754.0</td>\n",
              "      <td>5170.0</td>\n",
              "      <td>5170.0</td>\n",
              "      <td>5170.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      retweetCount                           ...                        \n",
              "             count         mean         std  ...     50%     75%     max\n",
              "group                                        ...                        \n",
              "0          11561.0    40.684456   54.761859  ...    13.0    71.0   230.0\n",
              "1           1722.0  1233.387921  186.720006  ...  1333.0  1333.0  2507.0\n",
              "2           1648.0   428.760316  160.371473  ...   331.0   637.0   762.0\n",
              "3              9.0  4698.000000  708.000000  ...  5170.0  5170.0  5170.0\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqJU-rSE4cWE",
        "colab_type": "text"
      },
      "source": [
        "### Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-iTe3JOpUrc",
        "colab_type": "code",
        "outputId": "a318cd88-7e14-40e0-9b3d-963c8ef661cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "#function to remove a certain pattern in the text\n",
        "def remove_pattern(input_txt, pattern):  \n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i, '', input_txt)\n",
        "        \n",
        "    return input_txt\n",
        "  \n",
        "data['text'] = np.vectorize(remove_pattern)(data['text'], \"@[\\w]*\")\n",
        "data['text'].head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    RT : Critical question: Was PayTM informed abo...\n",
              "1    RT : Did you vote on #Demonetization on Modi s...\n",
              "2    RT : Former FinSec, RBI Dy Governor, CBDT Chai...\n",
              "3    RT : Gurugram (Haryana): Post office employees...\n",
              "4    RT : Reddy Wedding!  cartoon #demonetization #...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XMf90G5pUrm",
        "colab_type": "code",
        "outputId": "89ab9589-18cf-4f28-975c-f4a071cf198a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "#Removing all characters beside alphabets and #\n",
        "data['text'] = data['text'].str.replace(\"[^a-zA-Z#]\", \" \") \n",
        "data['text'].head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    RT   Critical question  Was PayTM informed abo...\n",
              "1    RT   Did you vote on #Demonetization on Modi s...\n",
              "2    RT   Former FinSec  RBI Dy Governor  CBDT Chai...\n",
              "3    RT   Gurugram  Haryana   Post office employees...\n",
              "4    RT   Reddy Wedding   cartoon #demonetization #...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bgkCLQXpUrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing all words of size less than 3 like 'the', 'and' which do not represent any sentiment and do not play a role in predicting the outcome\n",
        "data['text'] = data['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsN1lQ--pUr8",
        "colab_type": "code",
        "outputId": "e37027bf-0719-47e2-98a0-8b4eea137a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#tokenization - creating tokens for words\n",
        "\n",
        "tokenized_tweet = data['text'].apply(lambda x: x.split())\n",
        "tokenized_tweet.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [Critical, question, PayTM, informed, about, #...\n",
              "1                [vote, #Demonetization, Modi, survey]\n",
              "2    [Former, FinSec, Governor, CBDT, Chair, Harvar...\n",
              "3    [Gurugram, Haryana, Post, office, employees, p...\n",
              "4    [Reddy, Wedding, cartoon, #demonetization, #Re...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Atx2adpUsD",
        "colab_type": "code",
        "outputId": "5335730c-f9df-4aea-aa4f-91a180467144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Stemmming - to have a single word for words having the same meaning but used in different forms like play, playing, played etc. \n",
        "\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
        "tokenized_tweet.head()\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [critic, question, paytm, inform, about, #demo...\n",
              "1                       [vote, #demonet, modi, survey]\n",
              "2    [former, finsec, governor, cbdt, chair, harvar...\n",
              "3    [gurugram, haryana, post, offic, employe, prov...\n",
              "4    [reddi, wed, cartoon, #demonet, #reddywed, htt...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbJfxnv3pUsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clubbing the words/ tokens back to sentences\n",
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1sjdh3iuQe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using Keras preprocessing functions for preparing the input dataset\n",
        "\n",
        "#tokenizing the processed text again\n",
        "tk = Tokenizer(lower = True)\n",
        "tk.fit_on_texts(tokenized_tweet)               \n",
        "\n",
        "#representing the word by a number equal to the frequency of its occcurence.\n",
        "X_seq = tk.texts_to_sequences(tokenized_tweet)   \n",
        "\n",
        "#limiting the length of each sentence to 100. Padding with 0 if sentence is short\n",
        "X_pad = pad_sequences(X_seq, maxlen=100, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwg2Elrb6V81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Binarizing the output label i.e. representing each label in binary format\n",
        "\n",
        "from sklearn import preprocessing\n",
        "y = data['group']\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(y)\n",
        "m = lb.transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B-axkYO2er9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing train and test datasets\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X_pad, m, y  = shuffle(X_pad, m, y, random_state = 0)\n",
        "X_train = X_pad[:-4000]\n",
        "X_test  = X_pad[-4000:]\n",
        "y_train = m[:-4000]\n",
        "y_test = m[-4000:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFCY_B1v-sUM",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n",
        "### 1. Classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvvJBJ5N2wA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  vocabulary_size = len(tk.word_counts.keys())+1\n",
        "  max_words = 100\n",
        "  embedding_size = 32\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(100, kernel_size=8, activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=4))\n",
        "  model.add(LSTM(200,return_sequences=True))\n",
        "  model.add(LSTM(200))\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhRe9VtA4L2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " estimator = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecpr0kkXphWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N7YrtHuplw5",
        "colab_type": "code",
        "outputId": "667261e4-447b-4a4a-9c30-ce49ca0e09bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "results = cross_val_score(estimator, X_pad, y, cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Baseline: 98.76% (0.18%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKSCrzx7Zr0G",
        "colab_type": "text"
      },
      "source": [
        "Classification Accuracy = **98.76%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smwOydYCjV4R",
        "colab_type": "text"
      },
      "source": [
        "###2.  Precision and recall using confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIR6atR3YtXP",
        "colab_type": "code",
        "outputId": "fce65703-e2b8-4d61-fa5e-c66b041114c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "# using confusion matrix\n",
        "model = create_model()\n",
        "\n",
        "clf = model.fit(X_train, y_train, epochs = 15, batch_size = 500)\n",
        "\n",
        "out = model.predict(X_test)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10940/10940 [==============================] - 31s 3ms/step - loss: 0.8711 - acc: 0.7446\n",
            "Epoch 2/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.7012 - acc: 0.7725\n",
            "Epoch 3/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.6969 - acc: 0.7725\n",
            "Epoch 4/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.5514 - acc: 0.7797\n",
            "Epoch 5/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.2350 - acc: 0.9211\n",
            "Epoch 6/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0991 - acc: 0.9766\n",
            "Epoch 7/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0669 - acc: 0.9845\n",
            "Epoch 8/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0559 - acc: 0.9869\n",
            "Epoch 9/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0500 - acc: 0.9878\n",
            "Epoch 10/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0478 - acc: 0.9879\n",
            "Epoch 11/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0471 - acc: 0.9881\n",
            "Epoch 12/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0431 - acc: 0.9883\n",
            "Epoch 13/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0390 - acc: 0.9899\n",
            "Epoch 14/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0380 - acc: 0.9905\n",
            "Epoch 15/15\n",
            "10940/10940 [==============================] - 28s 3ms/step - loss: 0.0393 - acc: 0.9903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUs6Xk8-j80f",
        "colab_type": "text"
      },
      "source": [
        "The predicted output will be floating point values and must be rounded to the nearest integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhdfyzM_lv1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The predicted output will be floating point values and must be rounded to the nearest integers\n",
        "\n",
        "out1 = np.round(out)\n",
        "k = out1.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv_rm_vJ_shp",
        "colab_type": "code",
        "outputId": "cbd95232-9182-4cd0-e62e-8f3a64e33ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "multilabel_confusion_matrix(y_test, k, labels = [0,1,2,3])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 882,    8],\n",
              "        [  68, 3042]],\n",
              "\n",
              "       [[3487,   58],\n",
              "        [   3,  452]],\n",
              "\n",
              "       [[3557,   10],\n",
              "        [  20,  413]],\n",
              "\n",
              "       [[3998,    0],\n",
              "        [   2,    0]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H-AegLsWYaQ",
        "colab_type": "text"
      },
      "source": [
        "Precision = True Positives / (True Positives + False Positives);\n",
        "Recall  = True Positives / (True Positives + Falsev Negatives);\n",
        "\n",
        "True positives = 3042 + 452 + 413 + 0 = 3907;\n",
        "False Negatives = 68 + 3 + 20 + 2 = 93;\n",
        "False Positives = 8 + 58 + 10 + 0 = 76; \n",
        "\n",
        " Precision = **98**;\n",
        " Recall = **97.6;**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZUhxktuYDP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}